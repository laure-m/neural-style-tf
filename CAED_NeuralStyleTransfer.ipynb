{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAED_NeuralStyleTransfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laure-m/neural-style-tf/blob/main/CAED_NeuralStyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMufyFRUfCwd"
      },
      "source": [
        "# CAED.STUDIO NEURAL STYLE TRANSFER NOTEBOOK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MD6jFZyfIjH"
      },
      "source": [
        "**IMPORTANT:** Read all text before running the cell as some directions can change parameters or might download to the incorrect folder \n",
        "Read the output of each cell after you run it > if you get an error or something didnt load or it cant find a folder or image then SOMETHING IS WRONG.    \n",
        "     \n",
        "#**PART 00 | DOWNLOAD THINGS**\n",
        "Download the neural-style-tf repository from my GitHub, extract it and upload it to your Google Drive. \n",
        "\n",
        "You then need to Download the VGG-19 network (can be found https://www.robots.ox.ac.uk/~vgg/research/very_deep/). After downloading, copy the weights file *imagenet-vgg-verydeep-19.mat* directly into the project directory (Inside neural-style-transfer folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HqfXczjfL4C"
      },
      "source": [
        "#**PART 01 | THE SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iqyfozce_as",
        "cellView": "form"
      },
      "source": [
        "#@title **STEP 00:**  Mount to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXKJe7gwfvCv",
        "cellView": "form"
      },
      "source": [
        "#@title **STEP 01:**  Change Directory to the neural-style-tf-master folder\n",
        "%cd /content/drive/My\\ Drive/neural-style-tf-master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJe71S6gbzt3",
        "cellView": "form"
      },
      "source": [
        "#@title **STEP 02:** Check Your Equipment\n",
        "#@markdown This cell connects to Google to tell us which GPU they gave us\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOda9jQw-2mD",
        "cellView": "form"
      },
      "source": [
        "#@title **STEP 03:** Install Required Libraries\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJQz21rDgKen",
        "cellView": "form"
      },
      "source": [
        "#@title **STEP 04:** Set Tensorflow to 1.15\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLmjZai-ggoj"
      },
      "source": [
        "#**PART 02 | SINGLE IMAGE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSlIsz-hkBHA"
      },
      "source": [
        "*Arguments You Can Change*\n",
        "\n",
        "*   `content_img`: Filename of the content image. Example: lion.jpg\n",
        "*   `content_img_dir`: Relative or absolute directory path to the content image. Default: ./image_input\n",
        "*   `style_imgs`: Filenames of the style images. To use multiple style images, pass a space-separated list. Ex: --style_imgs starry-night.jpg\n",
        "-`style_imgs_weights`: The blending weights for each style image. Default: 1.0 (assumes only 1 style image)\n",
        "-`style_imgs_dir`: Relative or absolute directory path to the style images. Default: ./styles\n",
        "-`init_img_type`: Image used to initialize the network. Choices: content, random, style. Default: content\n",
        "-`max_size`: Maximum width or height of the input images. Default: 512\n",
        "-`content_weight`: Weight for the content loss function. Default: 5e0\n",
        "-`style_weight`: Weight for the style loss function. Default: 1e4\n",
        "-`original_colors`: Boolean flag indicating if the style is transferred but not the colors.\n",
        "-`seed`: Seed for the random number generator. Default: 0\n",
        "-`img_output_dir`: Directory to write output to. Default: ./image_output\n",
        "-`img_name`: Filename of the output image. Default: result\n",
        "-`verbose`: Boolean flag indicating if statements should be printed to the console.\n",
        "-`max_iterations`: Max number of iterations for the Adam or L-BFGS optimizer. Default: 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZP8fJTi1F7"
      },
      "source": [
        "**STEP 05:** Set Parameters for an Image and Run it   \n",
        "The output image will show up in the image_output folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvwbU1rbgVUv"
      },
      "source": [
        "!python neural_style_edit.py --content_img golden_gate.jpg --style_imgs cg1.jpg --content_weight 5 --style_weight 1000 --max_size 512  --max_iterations 800    --verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqHEVFf8hyy3"
      },
      "source": [
        "#**PART 03 | VIDEO FRAMES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMwE_2q2kxHy"
      },
      "source": [
        "*Video Frame Specific Arguments*  \n",
        "\n",
        "*   `video`: Boolean flag indicating if the user is creating a video.\n",
        "*   `start_frame`: First frame number. Default: 1\n",
        "-`end_frame`: Last frame number. Default: 1\n",
        "-`first_frame_type`: Image used to initialize the network during the rendering of the first frame. Choices: content, random, style. Default: random\n",
        "-`init_frame_type`: Image used to initialize the network during the every rendering after the first frame. Choices: prev_warped, prev, content, random, style. Default: prev_warped\n",
        "-`video_input_dir`: Relative or absolute directory path to input frames. Default: ./video_input\n",
        "-`video_output_dir`: Relative or absolute directory path to write output frames to. Default: ./video_output\n",
        "-`content_frame_frmt`: Format string of input frames. Default: frame_{}.png\n",
        "-`content_weights_frmt`: Format string of optical flow consistency files. Default: reliable_{}_{}.txt\n",
        "-`first_frame_iterations`: Maximum number of optimizer iterations of the first frame. Default: 2000\n",
        "-`frame_iterations`: Maximum number of optimizer iterations for each frame after the first frame. Default: 800"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHE_aHfbi681"
      },
      "source": [
        "**STEP 06:** Set Parameters for Video and Run it   \n",
        "The output frames will show up in the video_output folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6o0kd9gh7BJ"
      },
      "source": [
        "!python neural_style_edit.py --video --video_input_dir ./video_input/my_video_frames --style_imgs cg1.jpg  --content_frame_frmt collage_{}.png --content_weight 5 --style_weight 1000 --temporal_weight 1000   --content_layer_weights 1 --start_frame 1 --end_frame 4 --max_size 512 --first_frame_iterations 800 --frame_iterations 800 --verbose --init_frame_type style --first_frame_type style"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgqWnulQzQFZ"
      },
      "source": [
        "This notebook was put together by Laure Michelon at https://github.com/laure-m"
      ]
    }
  ]
}