{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class_NeuralStyleTransfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laure-m/neural-style-tf/blob/main/Class_NeuralStyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMufyFRUfCwd"
      },
      "source": [
        "# STUDIO NEURAL STYLE TRANSFER NOTEBOOK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MD6jFZyfIjH"
      },
      "source": [
        "**IMPORTANT:** Read all text before running the cell as some directions can change parameters or might download to the incorrect folder \n",
        "Read the output of each cell after you run it > if you get an error or something didnt load or it cant find a folder or image then SOMETHING IS WRONG.    \n",
        "     \n",
        "#**PART 00 | DOWNLOAD THINGS**\n",
        "Download the neural-style-tf repository from my GitHub, extract it and upload it to your Google Drive. \n",
        "\n",
        "You then need to Download the VGG-19 network (can be found https://www.robots.ox.ac.uk/~vgg/research/very_deep/). After downloading, copy the weights file *imagenet-vgg-verydeep-19.mat* directly into the project directory (Inside neural-style-transfer folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HqfXczjfL4C"
      },
      "source": [
        "#**PART 01 | THE SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iqyfozce_as",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c593de-35db-4492-ad50-b7acca31aaa6"
      },
      "source": [
        "#@title Mount to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the Style Transfer Folder\n",
        "%cd /content/drive/MyDrive\n",
        "!mkdir neural-style-tf\n",
        "!git clone https://github.com/laure-m/neural-style-tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOB7BUK1Xnbb",
        "outputId": "8e779f0f-7169-449a-ac43-5c874d1fbf76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'neural-style-tf'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 59 (delta 18), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXKJe7gwfvCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff5e161-6cf7-4119-9d31-a4f31c4f0eef"
      },
      "source": [
        "#@title Change Directory to the neural-style-tf-master folder\n",
        "%cd /content/drive/MyDrive/neural-style-tf/neural-style-tf-master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/neural-style-tf-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAKE SURE THE VGG MODEL IS INSIDE THE neural-style-tf-master FOLDER BEFORE NEXT STEP"
      ],
      "metadata": {
        "id": "iGM7Nn_aeffV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOda9jQw-2mD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1aa1a56-49ad-447e-ee56-5f07327e0788"
      },
      "source": [
        "#@title Install Required Libraries\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJQz21rDgKen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3325b2eb-755f-4533-bebd-700e23188316"
      },
      "source": [
        "#@title Set Tensorflow to 1.15\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 66.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.47.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=a0c117cf42c0a3a9fe4f187a7bd472c04c1a40399c01cac2cbbbabbef8c2fdeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLmjZai-ggoj"
      },
      "source": [
        "#**PART 02 | SINGLE IMAGE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSlIsz-hkBHA"
      },
      "source": [
        "*Arguments You Can Change*\n",
        "\n",
        "*   `content_img`: Filename of the content image. Example: lion.jpg\n",
        "*   `content_img_dir`: Relative or absolute directory path to the content image. Default: ./image_input\n",
        "*   `style_imgs`: Filenames of the style images. To use multiple style images, pass a space-separated list. Ex: --style_imgs starry-night.jpg\n",
        "-`style_imgs_weights`: The blending weights for each style image. Default: 1.0 (assumes only 1 style image)\n",
        "-`style_imgs_dir`: Relative or absolute directory path to the style images. Default: ./styles\n",
        "-`init_img_type`: Image used to initialize the network. Choices: content, random, style. Default: content\n",
        "-`max_size`: Maximum width or height of the input images. Default: 512\n",
        "-`content_weight`: Weight for the content loss function. Default: 5e0\n",
        "-`style_weight`: Weight for the style loss function. Default: 1e4\n",
        "-`original_colors`: Boolean flag indicating if the style is transferred but not the colors.\n",
        "-`seed`: Seed for the random number generator. Default: 0\n",
        "-`img_output_dir`: Directory to write output to. Default: ./image_output\n",
        "-`img_name`: Filename of the output image. Default: result\n",
        "-`verbose`: Boolean flag indicating if statements should be printed to the console.\n",
        "-`max_iterations`: Max number of iterations for the Adam or L-BFGS optimizer. Default: 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZP8fJTi1F7"
      },
      "source": [
        "**STEP 05:** Set Parameters for an Image and Run it   \n",
        "The output image will show up in the image_output folder."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7/6/22 --content_weight 5 --style_weight 1000 --max_size 512  --max_iterations 800"
      ],
      "metadata": {
        "id": "QsG4Sjq1rlii"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvwbU1rbgVUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de584488-b4d4-4196-f095-ffffcec2e26d"
      },
      "source": [
        "%cd /content/drive/MyDrive/neural-style-tf/neural-style-tf-master\n",
        "!python neural_style_edit.py --content_img Laure_Composition.png --style_imgs mb1.PNG --content_weight 5 --style_weight 3000 --max_size 1080  --max_iterations 2000    --verbose"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/neural-style-tf/neural-style-tf-master\n",
            "\n",
            "---- RENDERING SINGLE IMAGE ----\n",
            "\n",
            "WARNING:tensorflow:From neural_style_edit.py:550: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2022-08-05 00:56:54.113105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-08-05 00:56:54.141116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-05 00:56:54.141744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-08-05 00:56:54.142046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-05 00:56:54.143311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-08-05 00:56:54.144340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-08-05 00:56:54.144646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-08-05 00:56:54.145925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-08-05 00:56:54.146923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-08-05 00:56:54.150062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-05 00:56:54.150157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-05 00:56:54.151133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-05 00:56:54.151737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-08-05 00:56:54.152127: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2022-08-05 00:56:54.156565: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000204999 Hz\n",
            "2022-08-05 00:56:54.156932: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a05d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-08-05 00:56:54.156967: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-08-05 00:56:54.236575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-05 00:56:54.237410: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7924c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-08-05 00:56:54.237451: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2022-08-05 00:56:54.237682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-05 00:56:54.238311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-08-05 00:56:54.238397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-05 00:56:54.238420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-08-05 00:56:54.238440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-08-05 00:56:54.238472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-08-05 00:56:54.238490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-08-05 00:56:54.238509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-08-05 00:56:54.238529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-05 00:56:54.238599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-05 00:56:54.239213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-05 00:56:54.239748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-08-05 00:56:54.239823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-05 00:56:54.240981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-08-05 00:56:54.241031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-08-05 00:56:54.241049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-08-05 00:56:54.241177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-05 00:56:54.241772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-05 00:56:54.242347: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-08-05 00:56:54.242389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "\n",
            "BUILDING VGG-19 NETWORK\n",
            "loading model weights...\n",
            "constructing layers...\n",
            "LAYER GROUP 1\n",
            "--conv1_1 | shape=(1, 607, 1080, 64) | weights_shape=(3, 3, 3, 64)\n",
            "--relu1_1 | shape=(1, 607, 1080, 64) | bias_shape=(64,)\n",
            "--conv1_2 | shape=(1, 607, 1080, 64) | weights_shape=(3, 3, 64, 64)\n",
            "--relu1_2 | shape=(1, 607, 1080, 64) | bias_shape=(64,)\n",
            "WARNING:tensorflow:From neural_style_edit.py:325: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "--pool1   | shape=(1, 304, 540, 64)\n",
            "LAYER GROUP 2\n",
            "--conv2_1 | shape=(1, 304, 540, 128) | weights_shape=(3, 3, 64, 128)\n",
            "--relu2_1 | shape=(1, 304, 540, 128) | bias_shape=(128,)\n",
            "--conv2_2 | shape=(1, 304, 540, 128) | weights_shape=(3, 3, 128, 128)\n",
            "--relu2_2 | shape=(1, 304, 540, 128) | bias_shape=(128,)\n",
            "--pool2   | shape=(1, 152, 270, 128)\n",
            "LAYER GROUP 3\n",
            "--conv3_1 | shape=(1, 152, 270, 256) | weights_shape=(3, 3, 128, 256)\n",
            "--relu3_1 | shape=(1, 152, 270, 256) | bias_shape=(256,)\n",
            "--conv3_2 | shape=(1, 152, 270, 256) | weights_shape=(3, 3, 256, 256)\n",
            "--relu3_2 | shape=(1, 152, 270, 256) | bias_shape=(256,)\n",
            "--conv3_3 | shape=(1, 152, 270, 256) | weights_shape=(3, 3, 256, 256)\n",
            "--relu3_3 | shape=(1, 152, 270, 256) | bias_shape=(256,)\n",
            "--conv3_4 | shape=(1, 152, 270, 256) | weights_shape=(3, 3, 256, 256)\n",
            "--relu3_4 | shape=(1, 152, 270, 256) | bias_shape=(256,)\n",
            "--pool3   | shape=(1, 76, 135, 256)\n",
            "LAYER GROUP 4\n",
            "--conv4_1 | shape=(1, 76, 135, 512) | weights_shape=(3, 3, 256, 512)\n",
            "--relu4_1 | shape=(1, 76, 135, 512) | bias_shape=(512,)\n",
            "--conv4_2 | shape=(1, 76, 135, 512) | weights_shape=(3, 3, 512, 512)\n",
            "--relu4_2 | shape=(1, 76, 135, 512) | bias_shape=(512,)\n",
            "--conv4_3 | shape=(1, 76, 135, 512) | weights_shape=(3, 3, 512, 512)\n",
            "--relu4_3 | shape=(1, 76, 135, 512) | bias_shape=(512,)\n",
            "--conv4_4 | shape=(1, 76, 135, 512) | weights_shape=(3, 3, 512, 512)\n",
            "--relu4_4 | shape=(1, 76, 135, 512) | bias_shape=(512,)\n",
            "--pool4   | shape=(1, 38, 68, 512)\n",
            "LAYER GROUP 5\n",
            "--conv5_1 | shape=(1, 38, 68, 512) | weights_shape=(3, 3, 512, 512)\n",
            "--relu5_1 | shape=(1, 38, 68, 512) | bias_shape=(512,)\n",
            "--conv5_2 | shape=(1, 38, 68, 512) | weights_shape=(3, 3, 512, 512)\n",
            "--relu5_2 | shape=(1, 38, 68, 512) | bias_shape=(512,)\n",
            "--conv5_3 | shape=(1, 38, 68, 512) | weights_shape=(3, 3, 512, 512)\n",
            "--relu5_3 | shape=(1, 38, 68, 512) | bias_shape=(512,)\n",
            "--conv5_4 | shape=(1, 38, 68, 512) | weights_shape=(3, 3, 512, 512)\n",
            "--relu5_4 | shape=(1, 38, 68, 512) | bias_shape=(512,)\n",
            "--pool5   | shape=(1, 19, 34, 512)\n",
            "2022-08-05 00:56:59.131192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-05 00:57:00.329838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "\n",
            "MINIMIZING LOSS USING: L-BFGS OPTIMIZER\n",
            "WARNING:tensorflow:From neural_style_edit.py:602: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =      1966680     M =           10\n",
            " This problem is unconstrained.\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  7.08850D+10    |proj g|=  1.72352D+05\n",
            "\n",
            "At iterate   50    f=  1.28712D+10    |proj g|=  4.69833D+04\n",
            "\n",
            "At iterate  100    f=  3.53737D+09    |proj g|=  1.30576D+04\n",
            "\n",
            "At iterate  150    f=  1.80721D+09    |proj g|=  2.51092D+03\n",
            "\n",
            "At iterate  200    f=  1.47628D+09    |proj g|=  3.11579D+03\n",
            "\n",
            "At iterate  250    f=  1.34734D+09    |proj g|=  1.31184D+03\n",
            "\n",
            "At iterate  300    f=  1.26816D+09    |proj g|=  9.65568D+02\n",
            "\n",
            "At iterate  350    f=  1.21045D+09    |proj g|=  8.18215D+02\n",
            "\n",
            "At iterate  400    f=  1.17056D+09    |proj g|=  1.80382D+03\n",
            "\n",
            "At iterate  450    f=  1.13595D+09    |proj g|=  9.68070D+02\n",
            "\n",
            "At iterate  500    f=  1.10795D+09    |proj g|=  9.71185D+02\n",
            "\n",
            "At iterate  550    f=  1.08133D+09    |proj g|=  1.98961D+03\n",
            "\n",
            "At iterate  600    f=  1.06041D+09    |proj g|=  1.35859D+03\n",
            "\n",
            "At iterate  650    f=  1.04343D+09    |proj g|=  6.62492D+02\n",
            "\n",
            "At iterate  700    f=  1.02892D+09    |proj g|=  1.43658D+03\n",
            "\n",
            "At iterate  750    f=  1.01518D+09    |proj g|=  4.69893D+02\n",
            "\n",
            "At iterate  800    f=  1.00344D+09    |proj g|=  5.92260D+02\n",
            "\n",
            "At iterate  850    f=  9.92749D+08    |proj g|=  4.53450D+02\n",
            "\n",
            "At iterate  900    f=  9.83490D+08    |proj g|=  9.09187D+02\n",
            "\n",
            "At iterate  950    f=  9.75502D+08    |proj g|=  3.28611D+02\n",
            "\n",
            "At iterate 1000    f=  9.68291D+08    |proj g|=  8.21258D+02\n",
            "\n",
            "At iterate 1050    f=  9.61825D+08    |proj g|=  3.87162D+02\n",
            "\n",
            "At iterate 1100    f=  9.56051D+08    |proj g|=  2.72321D+02\n",
            "\n",
            "At iterate 1150    f=  9.51054D+08    |proj g|=  4.46730D+02\n",
            "\n",
            "At iterate 1200    f=  9.46857D+08    |proj g|=  3.26490D+02\n",
            "\n",
            "At iterate 1250    f=  9.43134D+08    |proj g|=  4.61092D+02\n",
            "\n",
            "At iterate 1300    f=  9.39937D+08    |proj g|=  5.55224D+02\n",
            "\n",
            "At iterate 1350    f=  9.36740D+08    |proj g|=  4.27138D+02\n",
            "\n",
            "At iterate 1400    f=  9.33774D+08    |proj g|=  3.62678D+02\n",
            "\n",
            "At iterate 1450    f=  9.31153D+08    |proj g|=  4.17836D+02\n",
            "\n",
            "At iterate 1500    f=  9.28670D+08    |proj g|=  3.33232D+02\n",
            "\n",
            "At iterate 1550    f=  9.26340D+08    |proj g|=  4.63721D+02\n",
            "\n",
            "At iterate 1600    f=  9.24404D+08    |proj g|=  4.62446D+02\n",
            "\n",
            "At iterate 1650    f=  9.22524D+08    |proj g|=  3.41196D+02\n",
            "\n",
            "At iterate 1700    f=  9.20786D+08    |proj g|=  2.77449D+02\n",
            "\n",
            "At iterate 1750    f=  9.19375D+08    |proj g|=  1.77491D+02\n",
            "\n",
            "At iterate 1800    f=  9.17950D+08    |proj g|=  3.20570D+02\n",
            "\n",
            "At iterate 1850    f=  9.16691D+08    |proj g|=  4.43924D+02\n",
            "\n",
            "At iterate 1900    f=  9.15452D+08    |proj g|=  3.02744D+02\n",
            "\n",
            "At iterate 1950    f=  9.14282D+08    |proj g|=  2.69587D+02\n",
            "\n",
            "At iterate 2000    f=  9.13163D+08    |proj g|=  2.37020D+02\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            "*****   2000   2112      1     0     0   2.370D+02   9.132D+08\n",
            "  F =   913162752.00000000     \n",
            "\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
            "Single image elapsed time: 619.51922082901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgqWnulQzQFZ"
      },
      "source": [
        "This notebook was put together by Laure Michelon at https://github.com/laure-m"
      ]
    }
  ]
}